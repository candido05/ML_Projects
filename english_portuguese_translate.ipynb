{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1808362,
          "sourceType": "datasetVersion",
          "datasetId": 1074315
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "english_portuguese_translate",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/candido05/ML_Projects/blob/main/english_portuguese_translate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "nageshsingh_englishportuguese_translation_path = kagglehub.dataset_download('nageshsingh/englishportuguese-translation')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "0ak0UZ0--P4P"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:37:56.852007Z",
          "iopub.execute_input": "2025-02-21T14:37:56.852416Z",
          "iopub.status.idle": "2025-02-21T14:37:57.285031Z",
          "shell.execute_reply.started": "2025-02-21T14:37:56.852377Z",
          "shell.execute_reply": "2025-02-21T14:37:57.283814Z"
        },
        "id": "R8NAWJNQ-P4Q",
        "outputId": "28a75557-a5b2-4126-9656-e0898a396320"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/englishportuguese-translation/por.txt\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:37:57.286685Z",
          "iopub.execute_input": "2025-02-21T14:37:57.287217Z",
          "iopub.status.idle": "2025-02-21T14:37:57.858594Z",
          "shell.execute_reply.started": "2025-02-21T14:37:57.287151Z",
          "shell.execute_reply": "2025-02-21T14:37:57.857714Z"
        },
        "id": "XM82L_eo-P4R"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:37:57.859876Z",
          "iopub.execute_input": "2025-02-21T14:37:57.860292Z",
          "iopub.status.idle": "2025-02-21T14:37:57.864228Z",
          "shell.execute_reply.started": "2025-02-21T14:37:57.860268Z",
          "shell.execute_reply": "2025-02-21T14:37:57.863301Z"
        },
        "id": "V5sIC6DY-P4R"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"all\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:37:57.865299Z",
          "iopub.execute_input": "2025-02-21T14:37:57.865663Z",
          "iopub.status.idle": "2025-02-21T14:38:00.903417Z",
          "shell.execute_reply.started": "2025-02-21T14:37:57.865626Z",
          "shell.execute_reply": "2025-02-21T14:38:00.902144Z"
        },
        "id": "JncUfh2X-P4S",
        "outputId": "f1dcf64c-9ac6-4c3a-c005-e2ae2d6517e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading collection 'all'\n[nltk_data]    | \n[nltk_data]    | Downloading package abc to /usr/share/nltk_data...\n[nltk_data]    |   Package abc is already up-to-date!\n[nltk_data]    | Downloading package alpino to /usr/share/nltk_data...\n[nltk_data]    |   Package alpino is already up-to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n[nltk_data]    |       up-to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n[nltk_data]    |       up-to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n[nltk_data]    |       up-to-date!\n[nltk_data]    | Downloading package basque_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package basque_grammars is already up-to-date!\n[nltk_data]    | Downloading package bcp47 to /usr/share/nltk_data...\n[nltk_data]    |   Package bcp47 is already up-to-date!\n[nltk_data]    | Downloading package biocreative_ppi to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n[nltk_data]    | Downloading package bllip_wsj_no_aux to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n[nltk_data]    | Downloading package book_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package book_grammars is already up-to-date!\n[nltk_data]    | Downloading package brown to /usr/share/nltk_data...\n[nltk_data]    |   Package brown is already up-to-date!\n[nltk_data]    | Downloading package brown_tei to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package brown_tei is already up-to-date!\n[nltk_data]    | Downloading package cess_cat to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package cess_cat is already up-to-date!\n[nltk_data]    | Downloading package cess_esp to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package cess_esp is already up-to-date!\n[nltk_data]    | Downloading package chat80 to /usr/share/nltk_data...\n[nltk_data]    |   Package chat80 is already up-to-date!\n[nltk_data]    | Downloading package city_database to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package city_database is already up-to-date!\n[nltk_data]    | Downloading package cmudict to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package cmudict is already up-to-date!\n[nltk_data]    | Downloading package comparative_sentences to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package comparative_sentences is already up-to-\n[nltk_data]    |       date!\n[nltk_data]    | Downloading package comtrans to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package comtrans is already up-to-date!\n[nltk_data]    | Downloading package conll2000 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package conll2000 is already up-to-date!\n[nltk_data]    | Downloading package conll2002 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package conll2002 is already up-to-date!\n[nltk_data]    | Downloading package conll2007 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package conll2007 is already up-to-date!\n[nltk_data]    | Downloading package crubadan to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package crubadan is already up-to-date!\n[nltk_data]    | Downloading package dependency_treebank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package dependency_treebank is already up-to-date!\n[nltk_data]    | Downloading package dolch to /usr/share/nltk_data...\n[nltk_data]    |   Package dolch is already up-to-date!\n[nltk_data]    | Downloading package europarl_raw to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package europarl_raw is already up-to-date!\n[nltk_data]    | Downloading package extended_omw to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package extended_omw is already up-to-date!\n[nltk_data]    | Downloading package floresta to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package floresta is already up-to-date!\n[nltk_data]    | Downloading package framenet_v15 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package framenet_v15 is already up-to-date!\n[nltk_data]    | Downloading package framenet_v17 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package framenet_v17 is already up-to-date!\n[nltk_data]    | Downloading package gazetteers to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package gazetteers is already up-to-date!\n[nltk_data]    | Downloading package genesis to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package genesis is already up-to-date!\n[nltk_data]    | Downloading package gutenberg to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package gutenberg is already up-to-date!\n[nltk_data]    | Downloading package ieer to /usr/share/nltk_data...\n[nltk_data]    |   Package ieer is already up-to-date!\n[nltk_data]    | Downloading package inaugural to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package inaugural is already up-to-date!\n[nltk_data]    | Downloading package indian to /usr/share/nltk_data...\n[nltk_data]    |   Package indian is already up-to-date!\n[nltk_data]    | Downloading package jeita to /usr/share/nltk_data...\n[nltk_data]    |   Package jeita is already up-to-date!\n[nltk_data]    | Downloading package kimmo to /usr/share/nltk_data...\n[nltk_data]    |   Package kimmo is already up-to-date!\n[nltk_data]    | Downloading package knbc to /usr/share/nltk_data...\n[nltk_data]    |   Package knbc is already up-to-date!\n[nltk_data]    | Downloading package large_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package large_grammars is already up-to-date!\n[nltk_data]    | Downloading package lin_thesaurus to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n[nltk_data]    | Downloading package mac_morpho to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package mac_morpho is already up-to-date!\n[nltk_data]    | Downloading package machado to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package machado is already up-to-date!\n[nltk_data]    | Downloading package masc_tagged to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package masc_tagged is already up-to-date!\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n[nltk_data]    |       date!\n[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n[nltk_data]    |       up-to-date!\n[nltk_data]    | Downloading package moses_sample to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package moses_sample is already up-to-date!\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package movie_reviews is already up-to-date!\n[nltk_data]    | Downloading package mte_teip5 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package mte_teip5 is already up-to-date!\n[nltk_data]    | Downloading package mwa_ppdb to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n[nltk_data]    | Downloading package names to /usr/share/nltk_data...\n[nltk_data]    |   Package names is already up-to-date!\n[nltk_data]    | Downloading package nombank.1.0 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n[nltk_data]    | Downloading package nonbreaking_prefixes to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n[nltk_data]    | Downloading package nps_chat to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package nps_chat is already up-to-date!\n[nltk_data]    | Downloading package omw to /usr/share/nltk_data...\n[nltk_data]    |   Package omw is already up-to-date!\n[nltk_data]    | Downloading package omw-1.4 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package omw-1.4 is already up-to-date!\n[nltk_data]    | Downloading package opinion_lexicon to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n[nltk_data]    | Downloading package panlex_swadesh to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n[nltk_data]    | Downloading package paradigms to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package paradigms is already up-to-date!\n[nltk_data]    | Downloading package pe08 to /usr/share/nltk_data...\n[nltk_data]    |   Package pe08 is already up-to-date!\n[nltk_data]    | Downloading package perluniprops to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package perluniprops is already up-to-date!\n[nltk_data]    | Downloading package pil to /usr/share/nltk_data...\n[nltk_data]    |   Package pil is already up-to-date!\n[nltk_data]    | Downloading package pl196x to /usr/share/nltk_data...\n[nltk_data]    |   Package pl196x is already up-to-date!\n[nltk_data]    | Downloading package porter_test to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package porter_test is already up-to-date!\n[nltk_data]    | Downloading package ppattach to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package ppattach is already up-to-date!\n[nltk_data]    | Downloading package problem_reports to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package problem_reports is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_1 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_2 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n[nltk_data]    | Downloading package propbank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package propbank is already up-to-date!\n[nltk_data]    | Downloading package pros_cons to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package pros_cons is already up-to-date!\n[nltk_data]    | Downloading package ptb to /usr/share/nltk_data...\n[nltk_data]    |   Package ptb is already up-to-date!\n[nltk_data]    | Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]    |   Package punkt is already up-to-date!\n[nltk_data]    | Downloading package punkt_tab to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package punkt_tab is already up-to-date!\n[nltk_data]    | Downloading package qc to /usr/share/nltk_data...\n[nltk_data]    |   Package qc is already up-to-date!\n[nltk_data]    | Downloading package reuters to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package reuters is already up-to-date!\n[nltk_data]    | Downloading package rslp to /usr/share/nltk_data...\n[nltk_data]    |   Package rslp is already up-to-date!\n[nltk_data]    | Downloading package rte to /usr/share/nltk_data...\n[nltk_data]    |   Package rte is already up-to-date!\n[nltk_data]    | Downloading package sample_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sample_grammars is already up-to-date!\n[nltk_data]    | Downloading package semcor to /usr/share/nltk_data...\n[nltk_data]    |   Package semcor is already up-to-date!\n[nltk_data]    | Downloading package senseval to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package senseval is already up-to-date!\n[nltk_data]    | Downloading package sentence_polarity to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sentence_polarity is already up-to-date!\n[nltk_data]    | Downloading package sentiwordnet to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sentiwordnet is already up-to-date!\n[nltk_data]    | Downloading package shakespeare to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package shakespeare is already up-to-date!\n[nltk_data]    | Downloading package sinica_treebank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sinica_treebank is already up-to-date!\n[nltk_data]    | Downloading package smultron to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package smultron is already up-to-date!\n[nltk_data]    | Downloading package snowball_data to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package snowball_data is already up-to-date!\n[nltk_data]    | Downloading package spanish_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package spanish_grammars is already up-to-date!\n[nltk_data]    | Downloading package state_union to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package state_union is already up-to-date!\n[nltk_data]    | Downloading package stopwords to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package stopwords is already up-to-date!\n[nltk_data]    | Downloading package subjectivity to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package subjectivity is already up-to-date!\n[nltk_data]    | Downloading package swadesh to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package swadesh is already up-to-date!\n[nltk_data]    | Downloading package switchboard to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package switchboard is already up-to-date!\n[nltk_data]    | Downloading package tagsets to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package tagsets is already up-to-date!\n[nltk_data]    | Downloading package tagsets_json to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package tagsets_json is already up-to-date!\n[nltk_data]    | Downloading package timit to /usr/share/nltk_data...\n[nltk_data]    |   Package timit is already up-to-date!\n[nltk_data]    | Downloading package toolbox to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package toolbox is already up-to-date!\n[nltk_data]    | Downloading package treebank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package treebank is already up-to-date!\n[nltk_data]    | Downloading package twitter_samples to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package twitter_samples is already up-to-date!\n[nltk_data]    | Downloading package udhr to /usr/share/nltk_data...\n[nltk_data]    |   Package udhr is already up-to-date!\n[nltk_data]    | Downloading package udhr2 to /usr/share/nltk_data...\n[nltk_data]    |   Package udhr2 is already up-to-date!\n[nltk_data]    | Downloading package unicode_samples to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package unicode_samples is already up-to-date!\n[nltk_data]    | Downloading package universal_tagset to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package universal_tagset is already up-to-date!\n[nltk_data]    | Downloading package universal_treebanks_v20 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n[nltk_data]    |       date!\n[nltk_data]    | Downloading package vader_lexicon to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package vader_lexicon is already up-to-date!\n[nltk_data]    | Downloading package verbnet to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package verbnet is already up-to-date!\n[nltk_data]    | Downloading package verbnet3 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package verbnet3 is already up-to-date!\n[nltk_data]    | Downloading package webtext to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package webtext is already up-to-date!\n[nltk_data]    | Downloading package wmt15_eval to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wmt15_eval is already up-to-date!\n[nltk_data]    | Downloading package word2vec_sample to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package word2vec_sample is already up-to-date!\n[nltk_data]    | Downloading package wordnet to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet is already up-to-date!\n[nltk_data]    | Downloading package wordnet2021 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet2021 is already up-to-date!\n[nltk_data]    | Downloading package wordnet2022 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet2022 is already up-to-date!\n[nltk_data]    | Downloading package wordnet31 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet31 is already up-to-date!\n[nltk_data]    | Downloading package wordnet_ic to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet_ic is already up-to-date!\n[nltk_data]    | Downloading package words to /usr/share/nltk_data...\n[nltk_data]    |   Package words is already up-to-date!\n[nltk_data]    | Downloading package ycoe to /usr/share/nltk_data...\n[nltk_data]    |   Package ycoe is already up-to-date!\n[nltk_data]    | \n[nltk_data]  Done downloading collection all\n",
          "output_type": "stream"
        },
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:00.904697Z",
          "iopub.execute_input": "2025-02-21T14:38:00.905007Z",
          "iopub.status.idle": "2025-02-21T14:38:04.547151Z",
          "shell.execute_reply.started": "2025-02-21T14:38:00.90498Z",
          "shell.execute_reply": "2025-02-21T14:38:04.545957Z"
        },
        "id": "aXCgFf2W-P4S"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/kaggle/input/englishportuguese-translation/por.txt\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:04.548293Z",
          "iopub.execute_input": "2025-02-21T14:38:04.549056Z",
          "iopub.status.idle": "2025-02-21T14:38:04.553503Z",
          "shell.execute_reply.started": "2025-02-21T14:38:04.549023Z",
          "shell.execute_reply": "2025-02-21T14:38:04.552304Z"
        },
        "id": "k-sJIrHu-P4S"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(filepath, sep=\"\\t\", names=[\"En\", \"Pt\", \"NAN\"])[[\"En\", \"Pt\"]]\n",
        "df.head(10)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:04.558466Z",
          "iopub.execute_input": "2025-02-21T14:38:04.55883Z",
          "iopub.status.idle": "2025-02-21T14:38:05.267761Z",
          "shell.execute_reply.started": "2025-02-21T14:38:04.558792Z",
          "shell.execute_reply": "2025-02-21T14:38:05.266715Z"
        },
        "id": "UCs-xWMS-P4T",
        "outputId": "c0da74c1-278b-4895-d6ae-64614a944a3b"
      },
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     En       Pt\n0   Go.     Vai.\n1   Go.      Vá.\n2   Hi.      Oi.\n3  Run!   Corre!\n4  Run!   Corra!\n5  Run!  Corram!\n6  Run.   Corre!\n7  Run.   Corra!\n8  Run.  Corram!\n9  Who?    Quem?",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>En</th>\n      <th>Pt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go.</td>\n      <td>Vai.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Go.</td>\n      <td>Vá.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hi.</td>\n      <td>Oi.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Run!</td>\n      <td>Corre!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Run!</td>\n      <td>Corra!</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Run!</td>\n      <td>Corram!</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Run.</td>\n      <td>Corre!</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Run.</td>\n      <td>Corra!</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Run.</td>\n      <td>Corram!</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Who?</td>\n      <td>Quem?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:05.269709Z",
          "iopub.execute_input": "2025-02-21T14:38:05.270207Z",
          "iopub.status.idle": "2025-02-21T14:38:05.276449Z",
          "shell.execute_reply.started": "2025-02-21T14:38:05.270144Z",
          "shell.execute_reply": "2025-02-21T14:38:05.275315Z"
        },
        "id": "HEuGNG5q-P4T",
        "outputId": "1c2221f3-ff95-40cc-9cfc-482426a55e4f"
      },
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(168903, 2)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:05.27771Z",
          "iopub.execute_input": "2025-02-21T14:38:05.277988Z",
          "iopub.status.idle": "2025-02-21T14:38:05.322231Z",
          "shell.execute_reply.started": "2025-02-21T14:38:05.277964Z",
          "shell.execute_reply": "2025-02-21T14:38:05.320806Z"
        },
        "id": "ph5u5hCS-P4U",
        "outputId": "e35727e7-15f5-4376-ac22-3e5c052b3dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 168903 entries, 0 to 168902\nData columns (total 2 columns):\n #   Column  Non-Null Count   Dtype \n---  ------  --------------   ----- \n 0   En      168903 non-null  object\n 1   Pt      168903 non-null  object\ndtypes: object(2)\nmemory usage: 2.6+ MB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:05.323533Z",
          "iopub.execute_input": "2025-02-21T14:38:05.323875Z",
          "iopub.status.idle": "2025-02-21T14:38:05.429737Z",
          "shell.execute_reply.started": "2025-02-21T14:38:05.323846Z",
          "shell.execute_reply": "2025-02-21T14:38:05.428556Z"
        },
        "id": "MvzGWhNu-P4U",
        "outputId": "81d29d0b-ef57-410e-c925-d16f54bd5d0b"
      },
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head(10)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:05.430785Z",
          "iopub.execute_input": "2025-02-21T14:38:05.431208Z",
          "iopub.status.idle": "2025-02-21T14:38:05.483053Z",
          "shell.execute_reply.started": "2025-02-21T14:38:05.431144Z",
          "shell.execute_reply": "2025-02-21T14:38:05.481786Z"
        },
        "id": "tiw95bpi-P4U",
        "outputId": "d6c25c77-8324-448c-c16a-0a9ba51a43a0"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              En  \\\n0                Tom wasn't the only one crying.   \n1          The farmer employed five new workers.   \n2  I can't believe that you really believe that.   \n3                               I come in peace.   \n4                     Many thanks for your help.   \n5                      What's that in your hand?   \n6                               What a nice guy!   \n7                             Tom knows who won.   \n8                                   I'm curious.   \n9                    Stay here until I get back.   \n\n                                                  Pt  \n0                   Tom não era o único que chorava.  \n1   O fazendeiro contratou cinco novos funcionários.  \n2  Eu não acredito que você realmente acredita ni...  \n3                                      Venho em paz.  \n4                     Muito obrigado pela sua ajuda.  \n5                             Que é isso em sua mão?  \n6                                   Que cara bacana!  \n7                              Tom sabe quem ganhou.  \n8                                       Quero saber.  \n9                          Fique aqui até eu voltar.  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>En</th>\n      <th>Pt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Tom wasn't the only one crying.</td>\n      <td>Tom não era o único que chorava.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The farmer employed five new workers.</td>\n      <td>O fazendeiro contratou cinco novos funcionários.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I can't believe that you really believe that.</td>\n      <td>Eu não acredito que você realmente acredita ni...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I come in peace.</td>\n      <td>Venho em paz.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Many thanks for your help.</td>\n      <td>Muito obrigado pela sua ajuda.</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>What's that in your hand?</td>\n      <td>Que é isso em sua mão?</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>What a nice guy!</td>\n      <td>Que cara bacana!</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Tom knows who won.</td>\n      <td>Tom sabe quem ganhou.</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>I'm curious.</td>\n      <td>Quero saber.</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Stay here until I get back.</td>\n      <td>Fique aqui até eu voltar.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[:100000].copy()\n",
        "\n",
        "# Modificar a coluna de forma segura usando .loc\n",
        "data.loc[:, 'Pt'] = data['Pt'].apply(lambda x: \"<SOS> \" + x + \" <EOS>\")\n",
        "data.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:05.483998Z",
          "iopub.execute_input": "2025-02-21T14:38:05.484309Z",
          "iopub.status.idle": "2025-02-21T14:38:05.569716Z",
          "shell.execute_reply.started": "2025-02-21T14:38:05.484283Z",
          "shell.execute_reply": "2025-02-21T14:38:05.568576Z"
        },
        "id": "QrqE03gC-P4U",
        "outputId": "616af2d3-740e-4b80-f276-cd816a482e0a"
      },
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              En  \\\n0                Tom wasn't the only one crying.   \n1          The farmer employed five new workers.   \n2  I can't believe that you really believe that.   \n3                               I come in peace.   \n4                     Many thanks for your help.   \n\n                                                  Pt  \n0       <SOS> Tom não era o único que chorava. <EOS>  \n1  <SOS> O fazendeiro contratou cinco novos funci...  \n2  <SOS> Eu não acredito que você realmente acred...  \n3                          <SOS> Venho em paz. <EOS>  \n4         <SOS> Muito obrigado pela sua ajuda. <EOS>  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>En</th>\n      <th>Pt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Tom wasn't the only one crying.</td>\n      <td>&lt;SOS&gt; Tom não era o único que chorava. &lt;EOS&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The farmer employed five new workers.</td>\n      <td>&lt;SOS&gt; O fazendeiro contratou cinco novos funci...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I can't believe that you really believe that.</td>\n      <td>&lt;SOS&gt; Eu não acredito que você realmente acred...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I come in peace.</td>\n      <td>&lt;SOS&gt; Venho em paz. &lt;EOS&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Many thanks for your help.</td>\n      <td>&lt;SOS&gt; Muito obrigado pela sua ajuda. &lt;EOS&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def eng_preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # Corrigido regex e typo\n",
        "    text = nltk.word_tokenize(text)\n",
        "    text = \" \".join([i.strip() for i in text])\n",
        "    return text\n",
        "\n",
        "def pt_preprocess(text):\n",
        "    text = text.replace(\"\\u202f\", \" \")\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zéâàçêëôîû!?,\\'\\s]', ' ', text)  # Ajustado regex\n",
        "    return text"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:05.570599Z",
          "iopub.execute_input": "2025-02-21T14:38:05.570879Z",
          "iopub.status.idle": "2025-02-21T14:38:05.576547Z",
          "shell.execute_reply.started": "2025-02-21T14:38:05.570856Z",
          "shell.execute_reply": "2025-02-21T14:38:05.57539Z"
        },
        "id": "cnyX0A9m-P4V"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data['En'] = data['En'].apply(lambda x: eng_preprocess(x))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:05.577697Z",
          "iopub.execute_input": "2025-02-21T14:38:05.578081Z",
          "iopub.status.idle": "2025-02-21T14:38:14.324578Z",
          "shell.execute_reply.started": "2025-02-21T14:38:05.578054Z",
          "shell.execute_reply": "2025-02-21T14:38:14.323405Z"
        },
        "id": "p6ClvYnm-P4V"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:14.325717Z",
          "iopub.execute_input": "2025-02-21T14:38:14.326004Z",
          "iopub.status.idle": "2025-02-21T14:38:14.335873Z",
          "shell.execute_reply.started": "2025-02-21T14:38:14.325978Z",
          "shell.execute_reply": "2025-02-21T14:38:14.334593Z"
        },
        "id": "PcZi8pM4-P4V",
        "outputId": "c5bb1af7-33e8-4f6d-d1a1-dc649f02932c"
      },
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                            En  \\\n0                tom wasnt the only one crying   \n1         the farmer employed five new workers   \n2  i cant believe that you really believe that   \n3                              i come in peace   \n4                    many thanks for your help   \n\n                                                  Pt  \n0       <SOS> Tom não era o único que chorava. <EOS>  \n1  <SOS> O fazendeiro contratou cinco novos funci...  \n2  <SOS> Eu não acredito que você realmente acred...  \n3                          <SOS> Venho em paz. <EOS>  \n4         <SOS> Muito obrigado pela sua ajuda. <EOS>  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>En</th>\n      <th>Pt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tom wasnt the only one crying</td>\n      <td>&lt;SOS&gt; Tom não era o único que chorava. &lt;EOS&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the farmer employed five new workers</td>\n      <td>&lt;SOS&gt; O fazendeiro contratou cinco novos funci...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i cant believe that you really believe that</td>\n      <td>&lt;SOS&gt; Eu não acredito que você realmente acred...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i come in peace</td>\n      <td>&lt;SOS&gt; Venho em paz. &lt;EOS&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>many thanks for your help</td>\n      <td>&lt;SOS&gt; Muito obrigado pela sua ajuda. &lt;EOS&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data['Pt'] = data['Pt'].apply(lambda x: pt_preprocess(x))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:14.337283Z",
          "iopub.execute_input": "2025-02-21T14:38:14.337649Z",
          "iopub.status.idle": "2025-02-21T14:38:14.708249Z",
          "shell.execute_reply.started": "2025-02-21T14:38:14.337612Z",
          "shell.execute_reply": "2025-02-21T14:38:14.707029Z"
        },
        "id": "m5eEgyjC-P4V"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:14.709617Z",
          "iopub.execute_input": "2025-02-21T14:38:14.710031Z",
          "iopub.status.idle": "2025-02-21T14:38:14.720442Z",
          "shell.execute_reply.started": "2025-02-21T14:38:14.70999Z",
          "shell.execute_reply": "2025-02-21T14:38:14.719242Z"
        },
        "id": "Y7DiG-ep-P4V",
        "outputId": "fd17a052-cd48-42af-a3ac-ab1fa5c4597e"
      },
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                            En  \\\n0                tom wasnt the only one crying   \n1         the farmer employed five new workers   \n2  i cant believe that you really believe that   \n3                              i come in peace   \n4                    many thanks for your help   \n\n                                                  Pt  \n0        sos  tom n o era o  nico que chorava   eos   \n1   sos  o fazendeiro contratou cinco novos funci...  \n2   sos  eu n o acredito que você realmente acred...  \n3                           sos  venho em paz   eos   \n4          sos  muito obrigado pela sua ajuda   eos   ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>En</th>\n      <th>Pt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tom wasnt the only one crying</td>\n      <td>sos  tom n o era o  nico que chorava   eos</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the farmer employed five new workers</td>\n      <td>sos  o fazendeiro contratou cinco novos funci...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i cant believe that you really believe that</td>\n      <td>sos  eu n o acredito que você realmente acred...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i come in peace</td>\n      <td>sos  venho em paz   eos</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>many thanks for your help</td>\n      <td>sos  muito obrigado pela sua ajuda   eos</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_tokenization(feat):\n",
        "    eng_token = Tokenizer()\n",
        "    eng_token.fit_on_texts(feat)\n",
        "    eng_seq = eng_token.texts_to_sequences(feat)\n",
        "    return eng_seq, eng_token\n",
        "\n",
        "def target_tokenization(target):\n",
        "    port_token = Tokenizer()\n",
        "    port_token.fit_on_texts(target)\n",
        "    port_seq = port_token.texts_to_sequences(target)\n",
        "    return port_seq, port_token"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:14.721433Z",
          "iopub.execute_input": "2025-02-21T14:38:14.721742Z",
          "iopub.status.idle": "2025-02-21T14:38:14.735821Z",
          "shell.execute_reply.started": "2025-02-21T14:38:14.721718Z",
          "shell.execute_reply": "2025-02-21T14:38:14.734666Z"
        },
        "id": "vQLKqbI8-P4W"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "eng_sequences, eng_token = feature_tokenization(data['En'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:14.736844Z",
          "iopub.execute_input": "2025-02-21T14:38:14.737129Z",
          "iopub.status.idle": "2025-02-21T14:38:17.081806Z",
          "shell.execute_reply.started": "2025-02-21T14:38:14.737104Z",
          "shell.execute_reply": "2025-02-21T14:38:17.080752Z"
        },
        "id": "oYwZy1C7-P4W"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "eng_vocab = len(eng_token.word_index) + 1\n",
        "eng_vocab"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:17.082789Z",
          "iopub.execute_input": "2025-02-21T14:38:17.083065Z",
          "iopub.status.idle": "2025-02-21T14:38:17.089656Z",
          "shell.execute_reply.started": "2025-02-21T14:38:17.083042Z",
          "shell.execute_reply": "2025-02-21T14:38:17.088276Z"
        },
        "id": "drmHsFzX-P4W",
        "outputId": "ad6aed24-ed63-4aef-f0a4-f9a533f4cb49"
      },
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "10886"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "eng_sequences[:5]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:17.090763Z",
          "iopub.execute_input": "2025-02-21T14:38:17.091143Z",
          "iopub.status.idle": "2025-02-21T14:38:17.108971Z",
          "shell.execute_reply.started": "2025-02-21T14:38:17.091104Z",
          "shell.execute_reply": "2025-02-21T14:38:17.107625Z"
        },
        "id": "JlRlcI2K-P4W",
        "outputId": "875897c8-3bbc-4ace-f065-6e787e3fa9f1"
      },
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[[1, 121, 5, 146, 60, 643],\n [5, 2051, 5578, 524, 155, 2134],\n [2, 63, 221, 8, 4, 103, 221, 8],\n [2, 92, 10, 1536],\n [128, 527, 25, 30, 69]]"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "port_sequences, port_token = target_tokenization(data['Pt'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:17.115737Z",
          "iopub.execute_input": "2025-02-21T14:38:17.116139Z",
          "iopub.status.idle": "2025-02-21T14:38:19.772532Z",
          "shell.execute_reply.started": "2025-02-21T14:38:17.116109Z",
          "shell.execute_reply": "2025-02-21T14:38:19.771365Z"
        },
        "id": "x3i_QQCI-P4W"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "port_vocab = len(port_token.word_index) + 1\n",
        "port_vocab"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:19.77434Z",
          "iopub.execute_input": "2025-02-21T14:38:19.774617Z",
          "iopub.status.idle": "2025-02-21T14:38:19.780859Z",
          "shell.execute_reply.started": "2025-02-21T14:38:19.774594Z",
          "shell.execute_reply": "2025-02-21T14:38:19.77971Z"
        },
        "id": "oDAkASpy-P4W",
        "outputId": "6126370f-ce68-4c58-fa22-80fcd91cadb3"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "16444"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "port_sequences[:5]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:19.781994Z",
          "iopub.execute_input": "2025-02-21T14:38:19.782395Z",
          "iopub.status.idle": "2025-02-21T14:38:19.800026Z",
          "shell.execute_reply.started": "2025-02-21T14:38:19.782362Z",
          "shell.execute_reply": "2025-02-21T14:38:19.798742Z"
        },
        "id": "W64H0Ria-P4W",
        "outputId": "021fed06-3da9-4ca6-bce0-e13212a70502"
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[[1, 4, 5, 3, 82, 3, 424, 6, 3757, 2],\n [1, 3, 3064, 2444, 470, 1518, 4068, 480, 2],\n [1, 7, 5, 3, 516, 6, 10, 158, 895, 473, 2],\n [1, 1724, 21, 1192, 2],\n [1, 25, 362, 237, 54, 201, 2]]"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "port_inp = [x[:-1] for x in port_sequences]\n",
        "port_inp[:5]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:19.801256Z",
          "iopub.execute_input": "2025-02-21T14:38:19.801685Z",
          "iopub.status.idle": "2025-02-21T14:38:20.143685Z",
          "shell.execute_reply.started": "2025-02-21T14:38:19.801642Z",
          "shell.execute_reply": "2025-02-21T14:38:20.142478Z"
        },
        "id": "wju1y0Af-P4X",
        "outputId": "f5e498f3-55d8-46ea-950d-43368c069e34"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[[1, 4, 5, 3, 82, 3, 424, 6, 3757],\n [1, 3, 3064, 2444, 470, 1518, 4068, 480],\n [1, 7, 5, 3, 516, 6, 10, 158, 895, 473],\n [1, 1724, 21, 1192],\n [1, 25, 362, 237, 54, 201]]"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "port_out = [x[1:] for x in port_sequences]\n",
        "port_out[:5]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:20.144736Z",
          "iopub.execute_input": "2025-02-21T14:38:20.145049Z",
          "iopub.status.idle": "2025-02-21T14:38:20.198486Z",
          "shell.execute_reply.started": "2025-02-21T14:38:20.145023Z",
          "shell.execute_reply": "2025-02-21T14:38:20.196998Z"
        },
        "id": "YA64wF2u-P4X",
        "outputId": "a4a61324-9e56-46da-9415-099b4f24dbbd"
      },
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[[4, 5, 3, 82, 3, 424, 6, 3757, 2],\n [3, 3064, 2444, 470, 1518, 4068, 480, 2],\n [7, 5, 3, 516, 6, 10, 158, 895, 473, 2],\n [1724, 21, 1192, 2],\n [25, 362, 237, 54, 201, 2]]"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_seq(pad):\n",
        "    return pad_sequences(pad, padding = \"post\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:20.199481Z",
          "iopub.execute_input": "2025-02-21T14:38:20.199888Z",
          "iopub.status.idle": "2025-02-21T14:38:20.205016Z",
          "shell.execute_reply.started": "2025-02-21T14:38:20.199842Z",
          "shell.execute_reply": "2025-02-21T14:38:20.20385Z"
        },
        "id": "SPDBkXdW-P4X"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = pad_seq(eng_sequences)\n",
        "encoder_input = tf.convert_to_tensor(encoder_input)\n",
        "encoder_input"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:20.20606Z",
          "iopub.execute_input": "2025-02-21T14:38:20.206376Z",
          "iopub.status.idle": "2025-02-21T14:38:20.533134Z",
          "shell.execute_reply.started": "2025-02-21T14:38:20.206351Z",
          "shell.execute_reply": "2025-02-21T14:38:20.531766Z"
        },
        "id": "DTzLYwtg-P4X",
        "outputId": "df3012ef-4ef9-4569-dc92-9c28e168c4bc"
      },
      "outputs": [
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tf.Tensor: shape=(100000, 35), dtype=int32, numpy=\narray([[    1,   121,     5, ...,     0,     0,     0],\n       [    5,  2051,  5578, ...,     0,     0,     0],\n       [    2,    63,   221, ...,     0,     0,     0],\n       ...,\n       [  462, 10885,  5161, ...,     0,     0,     0],\n       [    1,    73,   111, ...,     0,     0,     0],\n       [   32,   146,    38, ...,     0,     0,     0]], dtype=int32)>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:20.53442Z",
          "iopub.execute_input": "2025-02-21T14:38:20.534812Z",
          "iopub.status.idle": "2025-02-21T14:38:20.542211Z",
          "shell.execute_reply.started": "2025-02-21T14:38:20.534768Z",
          "shell.execute_reply": "2025-02-21T14:38:20.541259Z"
        },
        "id": "akCAa-vQ-P4X",
        "outputId": "733c4554-62ed-4455-ff12-0b8dfbcd2b27"
      },
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TensorShape([100000, 35])"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input = pad_seq(port_inp)\n",
        "decoder_input = tf.convert_to_tensor(decoder_input)\n",
        "decoder_input"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:20.543249Z",
          "iopub.execute_input": "2025-02-21T14:38:20.543565Z",
          "iopub.status.idle": "2025-02-21T14:38:20.834623Z",
          "shell.execute_reply.started": "2025-02-21T14:38:20.543526Z",
          "shell.execute_reply": "2025-02-21T14:38:20.833325Z"
        },
        "id": "wBybcX1d-P4X",
        "outputId": "81f91962-b494-482f-e767-c988c35561b3"
      },
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tf.Tensor: shape=(100000, 35), dtype=int32, numpy=\narray([[    1,     4,     5, ...,     0,     0,     0],\n       [    1,     3,  3064, ...,     0,     0,     0],\n       [    1,     7,     5, ...,     0,     0,     0],\n       ...,\n       [    1,   522, 16443, ...,     0,     0,     0],\n       [    1,     4,   121, ...,     0,     0,     0],\n       [    1,    20,     5, ...,     0,     0,     0]], dtype=int32)>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:20.835661Z",
          "iopub.execute_input": "2025-02-21T14:38:20.835948Z",
          "iopub.status.idle": "2025-02-21T14:38:20.842213Z",
          "shell.execute_reply.started": "2025-02-21T14:38:20.835924Z",
          "shell.execute_reply": "2025-02-21T14:38:20.841044Z"
        },
        "id": "9fssa-Ru-P4X",
        "outputId": "c6b333b3-5925-4846-8643-569e9aaca8b1"
      },
      "outputs": [
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TensorShape([100000, 35])"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output = pad_seq(port_out)\n",
        "decoder_output = tf.convert_to_tensor(decoder_output)\n",
        "decoder_output"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:20.84357Z",
          "iopub.execute_input": "2025-02-21T14:38:20.843929Z",
          "iopub.status.idle": "2025-02-21T14:38:21.149775Z",
          "shell.execute_reply.started": "2025-02-21T14:38:20.843898Z",
          "shell.execute_reply": "2025-02-21T14:38:21.148534Z"
        },
        "id": "6N1-9oFu-P4Y",
        "outputId": "ad56f7d8-c304-448c-df29-14ae93e5e5a2"
      },
      "outputs": [
        {
          "execution_count": 32,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tf.Tensor: shape=(100000, 35), dtype=int32, numpy=\narray([[    4,     5,     3, ...,     0,     0,     0],\n       [    3,  3064,  2444, ...,     0,     0,     0],\n       [    7,     5,     3, ...,     0,     0,     0],\n       ...,\n       [  522, 16443,    36, ...,     0,     0,     0],\n       [    4,   121,   137, ...,     0,     0,     0],\n       [   20,     5,     3, ...,     0,     0,     0]], dtype=int32)>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:21.150851Z",
          "iopub.execute_input": "2025-02-21T14:38:21.15113Z",
          "iopub.status.idle": "2025-02-21T14:38:21.157525Z",
          "shell.execute_reply.started": "2025-02-21T14:38:21.151105Z",
          "shell.execute_reply": "2025-02-21T14:38:21.156327Z"
        },
        "id": "xh3qMLPL-P4Y",
        "outputId": "8ec3141e-d329-494c-ee3a-37d980920ca7"
      },
      "outputs": [
        {
          "execution_count": 33,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TensorShape([100000, 35])"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "eng_vocab = eng_vocab\n",
        "port_vocab = port_vocab\n",
        "\n",
        "eng_seq_len = encoder_input.shape[1]\n",
        "port_seq_len = decoder_input.shape[1]\n",
        "\n",
        "embed_dim = 180\n",
        "hidden_dim = 128\n",
        "\n",
        "num_heads = 6\n",
        "head_dim = embed_dim//num_heads\n",
        "\n",
        "num_blocks = 4"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:21.158509Z",
          "iopub.execute_input": "2025-02-21T14:38:21.15883Z",
          "iopub.status.idle": "2025-02-21T14:38:21.172644Z",
          "shell.execute_reply.started": "2025-02-21T14:38:21.158791Z",
          "shell.execute_reply": "2025-02-21T14:38:21.171491Z"
        },
        "id": "XT0L9okf-P4Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class positional_embedding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, vocab, sequence, embedding_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.vocab = vocab\n",
        "        self.sequence = sequence\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.embedding_layer = tf.keras.layers.Embedding(input_dim=self.vocab, output_dim=self.embedding_dim, input_length=self.sequence)\n",
        "        self.positional_encoding = tf.keras.layers.Embedding(self.sequence, self.embedding_dim)\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        pos_ids = tf.range(self.sequence)\n",
        "        token_embed = self.embedding_layer(inputs)\n",
        "        token_positional = self.positional_encoding(pos_ids)\n",
        "        final = token_embed + token_positional\n",
        "        return  final"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:21.173882Z",
          "iopub.execute_input": "2025-02-21T14:38:21.174325Z",
          "iopub.status.idle": "2025-02-21T14:38:21.191783Z",
          "shell.execute_reply.started": "2025-02-21T14:38:21.174286Z",
          "shell.execute_reply": "2025-02-21T14:38:21.19066Z"
        },
        "id": "WlR3bfoL-P4Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class padding_mask(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        mask = tf.cast(tf.math.not_equal(inputs, 0), tf.float32)\n",
        "        mask = mask[:, tf.newaxis, :]\n",
        "        return mask"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:21.192935Z",
          "iopub.execute_input": "2025-02-21T14:38:21.193374Z",
          "iopub.status.idle": "2025-02-21T14:38:21.203937Z",
          "shell.execute_reply.started": "2025-02-21T14:38:21.193338Z",
          "shell.execute_reply": "2025-02-21T14:38:21.202749Z"
        },
        "id": "IiEmzVy7-P4Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class look_ahead_mask(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.mask = padding_mask()\n",
        "\n",
        "    def call(self, inputs, sequence_length):\n",
        "        # Gera a máscara de padding\n",
        "        masked = self.mask(inputs)  # Forma: [batch_size, 1, sequence_length]\n",
        "\n",
        "        # Gera a máscara lookahead triangular\n",
        "        look = tf.linalg.band_part(tf.ones((sequence_length, sequence_length)), -1, 0)  # Forma: [sequence_length, sequence_length]\n",
        "        look = tf.expand_dims(tf.expand_dims(look, 0), 0)  # Forma: [1, 1, sequence_length, sequence_length]\n",
        "\n",
        "        # Combina as máscaras (padding e lookahead)\n",
        "        dec_mask = tf.minimum(masked[:, :, tf.newaxis, :], look)  # Forma: [batch_size, 1, sequence_length, sequence_length]\n",
        "\n",
        "        return dec_mask"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:21.204938Z",
          "iopub.execute_input": "2025-02-21T14:38:21.205321Z",
          "iopub.status.idle": "2025-02-21T14:38:21.218889Z",
          "shell.execute_reply.started": "2025-02-21T14:38:21.20529Z",
          "shell.execute_reply": "2025-02-21T14:38:21.217776Z"
        },
        "id": "no9y-V7s-P4Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class encoder_layer(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_heads, embedding_dim, hidden_dim, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim, dropout=dropout_rate)\n",
        "        self.norm1 = tf.keras.layers.LayerNormalization()\n",
        "        self.norm2 = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "        self.drop1 = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.drop2 = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(hidden_dim, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(hidden_dim, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(embedding_dim, activation=\"relu\"),\n",
        "            tf.keras.layers.Dropout(dropout_rate)\n",
        "        ])\n",
        "\n",
        "    def call(self, enc_inputs, enc_mask, training=False):  # 'training' como argumento nomeado\n",
        "        mha_out1 = self.mha(enc_inputs, enc_inputs, enc_inputs, enc_mask)\n",
        "        drop_out1 = self.drop1(mha_out1, training=training)\n",
        "        norm_out1 = self.norm1(self.add([drop_out1, enc_inputs]))\n",
        "\n",
        "        ffn_out = self.ffn(norm_out1)\n",
        "        drop_out2 = self.drop2(ffn_out, training=training)\n",
        "        final = self.norm2(self.add([drop_out2, norm_out1]))\n",
        "\n",
        "        return final"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:21.220035Z",
          "iopub.execute_input": "2025-02-21T14:38:21.220411Z",
          "iopub.status.idle": "2025-02-21T14:38:21.243034Z",
          "shell.execute_reply.started": "2025-02-21T14:38:21.22037Z",
          "shell.execute_reply": "2025-02-21T14:38:21.241952Z"
        },
        "id": "sL6C6swK-P4Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab, sequence, embedding_dim, num_heads, hidden_dim, num_blocks, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.pos = positional_embedding(vocab, sequence, embedding_dim)\n",
        "        self.mask = padding_mask()\n",
        "        self.encoder = [encoder_layer(num_heads, embedding_dim, hidden_dim) for _ in range(num_blocks)]\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "    def call(self, inputs, training=False):  # 'training' como argumento nomeado\n",
        "        emb = self.pos(inputs)\n",
        "        mask = self.mask(inputs)\n",
        "        temp = emb\n",
        "\n",
        "        for blocks in self.encoder:\n",
        "            emb = blocks(emb, mask, training=training)  # Passa 'training' como keyword argument\n",
        "            emb = self.add([temp, emb])\n",
        "            temp = emb\n",
        "\n",
        "        return emb, mask"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:21.244164Z",
          "iopub.execute_input": "2025-02-21T14:38:21.244527Z",
          "iopub.status.idle": "2025-02-21T14:38:21.266696Z",
          "shell.execute_reply.started": "2025-02-21T14:38:21.244498Z",
          "shell.execute_reply": "2025-02-21T14:38:21.265467Z"
        },
        "id": "tYJB8_lH-P4e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class decoder_layer(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_heads, embedding_dim, hidden_dim, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.mha1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim, dropout=dropout_rate)\n",
        "        self.mha2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim, dropout=dropout_rate)\n",
        "        self.norm1 = tf.keras.layers.LayerNormalization()\n",
        "        self.norm2 = tf.keras.layers.LayerNormalization()\n",
        "        self.norm3 = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "        self.drop1 = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.drop2 = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.drop3 = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(hidden_dim, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(hidden_dim, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(embedding_dim, activation=\"relu\"),\n",
        "            tf.keras.layers.Dropout(dropout_rate)\n",
        "        ])\n",
        "\n",
        "    def call(self, dec_inputs, enc_outputs, dec_mask, enc_mask, training=False):\n",
        "        mha_out1 = self.mha1(dec_inputs, dec_inputs, dec_inputs, attention_mask=dec_mask)\n",
        "        drop_out1 = self.drop1(mha_out1, training=training)\n",
        "        norm_out1 = self.norm1(self.add([drop_out1, dec_inputs]))\n",
        "\n",
        "        mha_out2 = self.mha2(norm_out1, enc_outputs, enc_outputs, attention_mask=enc_mask)\n",
        "        drop_out2 = self.drop2(mha_out2, training=training)\n",
        "        norm_out2 = self.norm2(self.add([drop_out2, norm_out1]))\n",
        "\n",
        "        ffn_out = self.ffn(norm_out2)\n",
        "        drop_out3 = self.drop3(ffn_out, training=training)\n",
        "        final = self.norm3(self.add([drop_out3, norm_out2]))\n",
        "\n",
        "        return final"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:21.267717Z",
          "iopub.execute_input": "2025-02-21T14:38:21.267995Z",
          "iopub.status.idle": "2025-02-21T14:38:21.287238Z",
          "shell.execute_reply.started": "2025-02-21T14:38:21.267972Z",
          "shell.execute_reply": "2025-02-21T14:38:21.286053Z"
        },
        "id": "lm07wIa7-P4e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab, sequence, embedding_dim, num_heads, hidden_dim, num_blocks, dropout_rate=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.sequence_length = sequence\n",
        "        self.pos = positional_embedding(vocab, sequence, embedding_dim)\n",
        "        self.look = look_ahead_mask()\n",
        "        self.decoder = [decoder_layer(num_heads, embedding_dim, hidden_dim) for _ in range(num_blocks)]\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "    def call(self, dec_inputs, encoder_outputs, enc_mask, training=False):\n",
        "        emb = self.pos(dec_inputs)\n",
        "        mask = self.look(dec_inputs, sequence_length=self.sequence_length)\n",
        "        temp = emb\n",
        "\n",
        "        for blocks in self.decoder:\n",
        "            emb = blocks(emb, encoder_outputs, mask, enc_mask, training=training)\n",
        "            emb = self.add([temp, emb])\n",
        "            temp = emb\n",
        "\n",
        "        return emb"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:21.288327Z",
          "iopub.execute_input": "2025-02-21T14:38:21.288734Z",
          "iopub.status.idle": "2025-02-21T14:38:21.309192Z",
          "shell.execute_reply.started": "2025-02-21T14:38:21.288693Z",
          "shell.execute_reply": "2025-02-21T14:38:21.308045Z"
        },
        "id": "cyQocEkJ-P4f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, eng_vocab, port_vocab, eng_seq_len, port_seq_len, embedding_dim, hidden_dim, num_heads, num_blocks, dropout_rate=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.encoder = Encoder(eng_vocab, eng_seq_len, embedding_dim, num_heads, hidden_dim, num_blocks)\n",
        "        self.decoder = Decoder(port_vocab, port_seq_len, embedding_dim, num_heads, hidden_dim, num_blocks)\n",
        "\n",
        "        self.Final_layer = tf.keras.layers.Dense(port_vocab, activation='relu')\n",
        "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        enc_inputs, dec_inputs = inputs\n",
        "\n",
        "        encoder_out, enc_mask = self.encoder(enc_inputs, training=training)\n",
        "        decoder_out = self.decoder(dec_inputs, encoder_out, enc_mask, training=training)\n",
        "\n",
        "        final = self.Final_layer(decoder_out)\n",
        "        softmaxed = self.softmax(final)\n",
        "\n",
        "        return softmaxed"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:21.310306Z",
          "iopub.execute_input": "2025-02-21T14:38:21.31061Z",
          "iopub.status.idle": "2025-02-21T14:38:21.326522Z",
          "shell.execute_reply.started": "2025-02-21T14:38:21.310583Z",
          "shell.execute_reply": "2025-02-21T14:38:21.325158Z"
        },
        "id": "w8rAmbS3-P4f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "transformers = Transformer(eng_vocab, port_vocab, eng_seq_len,\n",
        "                           port_seq_len, embed_dim, hidden_dim,\n",
        "                           num_heads, num_blocks)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:21.327696Z",
          "iopub.execute_input": "2025-02-21T14:38:21.328115Z",
          "iopub.status.idle": "2025-02-21T14:38:21.431399Z",
          "shell.execute_reply.started": "2025-02-21T14:38:21.328081Z",
          "shell.execute_reply": "2025-02-21T14:38:21.430152Z"
        },
        "id": "hzGMDG5U-P4f",
        "outputId": "71be7d4b-ccfa-45fb-837e-afe9508b05d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trans_out = transformers((encoder_input[:1], decoder_input[:1]), training=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:21.432334Z",
          "iopub.execute_input": "2025-02-21T14:38:21.432623Z",
          "iopub.status.idle": "2025-02-21T14:38:26.845305Z",
          "shell.execute_reply.started": "2025-02-21T14:38:21.432599Z",
          "shell.execute_reply": "2025-02-21T14:38:26.844149Z"
        },
        "id": "NW5PBm-B-P4f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trans_out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:26.846455Z",
          "iopub.execute_input": "2025-02-21T14:38:26.846752Z",
          "iopub.status.idle": "2025-02-21T14:38:26.853993Z",
          "shell.execute_reply.started": "2025-02-21T14:38:26.846718Z",
          "shell.execute_reply": "2025-02-21T14:38:26.852973Z"
        },
        "id": "vSIeO8GD-P4f",
        "outputId": "d1b32408-d3cd-429c-b0b3-c388a58892e6"
      },
      "outputs": [
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tf.Tensor: shape=(1, 35, 16444), dtype=float32, numpy=\narray([[[4.51336127e-05, 4.51336127e-05, 1.04714789e-04, ...,\n         4.51336127e-05, 4.51336127e-05, 4.51336127e-05],\n        [4.79636874e-05, 4.47269449e-05, 4.93040425e-05, ...,\n         9.50788672e-05, 4.47269449e-05, 6.78518118e-05],\n        [4.52583881e-05, 4.86424578e-05, 4.52583881e-05, ...,\n         4.96925168e-05, 4.52583881e-05, 4.52583881e-05],\n        ...,\n        [7.68870377e-05, 9.97956231e-05, 5.71735181e-05, ...,\n         4.50536427e-05, 4.50536427e-05, 4.50536427e-05],\n        [4.53077446e-05, 1.14522845e-04, 4.76471760e-05, ...,\n         4.53077446e-05, 4.53077446e-05, 5.49684773e-05],\n        [5.38023633e-05, 1.50434207e-04, 4.52935965e-05, ...,\n         4.52935965e-05, 4.52935965e-05, 4.83688091e-05]]], dtype=float32)>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "transformers.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:26.855051Z",
          "iopub.execute_input": "2025-02-21T14:38:26.855342Z",
          "iopub.status.idle": "2025-02-21T14:38:26.894513Z",
          "shell.execute_reply.started": "2025-02-21T14:38:26.855317Z",
          "shell.execute_reply": "2025-02-21T14:38:26.893396Z"
        },
        "id": "DQlzMPpi-P4f",
        "outputId": "85e8ba20-7d47-4c91-99c5-7f8040541533"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"transformer\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ encoder (\u001b[38;5;33mEncoder\u001b[0m)                    │ ?                           │       \u001b[38;5;34m5,344,340\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ decoder (\u001b[38;5;33mDecoder\u001b[0m)                    │ ?                           │       \u001b[38;5;34m9,470,300\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m16444\u001b[0m)              │       \u001b[38;5;34m2,976,364\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)                    │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)                    │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,344,340</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)                    │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">9,470,300</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16444</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,976,364</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)                    │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,791,004\u001b[0m (67.87 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,791,004</span> (67.87 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,791,004\u001b[0m (67.87 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,791,004</span> (67.87 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "transformers.get_build_config()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:26.895689Z",
          "iopub.execute_input": "2025-02-21T14:38:26.896077Z",
          "iopub.status.idle": "2025-02-21T14:38:26.906477Z",
          "shell.execute_reply.started": "2025-02-21T14:38:26.896036Z",
          "shell.execute_reply": "2025-02-21T14:38:26.905362Z"
        },
        "id": "r863lL0j-P4g",
        "outputId": "9c1f459f-9784-41c3-e449-05a3ed61451a"
      },
      "outputs": [
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'input_shape': ((1, 35), (1, 35))}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/kaggle/working/model.weights.h5\"\n",
        "transformers.save_weights(path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:26.907527Z",
          "iopub.execute_input": "2025-02-21T14:38:26.907932Z",
          "iopub.status.idle": "2025-02-21T14:38:27.354615Z",
          "shell.execute_reply.started": "2025-02-21T14:38:26.907889Z",
          "shell.execute_reply": "2025-02-21T14:38:27.353309Z"
        },
        "id": "OoDsvRl6-P4g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "compilation = transformers.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer=tf.keras.optimizers.RMSprop() ,metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:27.356027Z",
          "iopub.execute_input": "2025-02-21T14:38:27.356434Z",
          "iopub.status.idle": "2025-02-21T14:38:27.373884Z",
          "shell.execute_reply.started": "2025-02-21T14:38:27.356402Z",
          "shell.execute_reply": "2025-02-21T14:38:27.372597Z"
        },
        "id": "alCj8Wmd-P4g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "calls = tf.keras.callbacks.EarlyStopping(patience = 5, verbose = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:27.375102Z",
          "iopub.execute_input": "2025-02-21T14:38:27.375541Z",
          "iopub.status.idle": "2025-02-21T14:38:27.382762Z",
          "shell.execute_reply.started": "2025-02-21T14:38:27.375494Z",
          "shell.execute_reply": "2025-02-21T14:38:27.381753Z"
        },
        "id": "lb8_4viH-P4g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fitting = transformers.fit((encoder_input,decoder_input),decoder_output, validation_split=0.2, epochs = 100, batch_size = 500, verbose = True, callbacks = calls)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-21T14:38:27.383754Z",
          "iopub.execute_input": "2025-02-21T14:38:27.384074Z",
          "execution_failed": "2025-02-21T14:45:34.972Z"
        },
        "id": "a8QpP6JJ-P4g",
        "outputId": "b586c8cc-7cca-45f3-b18a-b567d54b3416"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/100\n\u001b[1m  7/160\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:13:50\u001b[0m 52s/step - accuracy: 0.3022 - loss: 7.7210",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "1tO62tI3-P4g"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}